{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "source": [
        "# Parameters cell\n",
        "csv_path = r'meter_meter_1_2025-04-30T20_53_43.157Z.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Initialize path variables\n",
        "base_path = r\"abfss://datalake@bessstorage.dfs.core.windows.net/bronze/\"\n",
        "csv_path = base_path + csv_path\n",
        "delta_path = csv_path.replace('.csv', '_delta')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Read CSV into spark df\n",
        "df_spark = spark.read.option(\"header\", True).csv(csv_path)\n",
        "\n",
        "# Print top 5 rows of spark df\n",
        "df_spark.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Write spark df as Delta Table\n",
        "df_spark.write.format(\"delta\").mode(\"overwrite\").save(delta_path)"
      ]
    }
  ]
}